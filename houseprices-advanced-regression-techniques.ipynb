{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a45b288",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-07-11T06:25:44.939679Z",
     "iopub.status.busy": "2022-07-11T06:25:44.938576Z",
     "iopub.status.idle": "2022-07-11T06:25:49.083509Z",
     "shell.execute_reply": "2022-07-11T06:25:49.081011Z"
    },
    "papermill": {
     "duration": 4.156821,
     "end_time": "2022-07-11T06:25:49.089251",
     "exception": false,
     "start_time": "2022-07-11T06:25:44.932430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/house-prices-advanced-regression-techniques/sample_submission.csv\n",
      "/kaggle/input/house-prices-advanced-regression-techniques/data_description.txt\n",
      "/kaggle/input/house-prices-advanced-regression-techniques/train.csv\n",
      "/kaggle/input/house-prices-advanced-regression-techniques/test.csv\n",
      "My Linear Regression R square score is: 0.8499687710975273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:130: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Random Forest Regression R square score is: 0.8647068670541247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Gradient Boosting Regression R square score is: 0.8902321258633148\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "'''\n",
    "Here, I will combine 3 different regression models, which are:\n",
    "\n",
    "1. Linear Regression\n",
    "2. Gradient Boost Regression\n",
    "3. Random Forest Regression\n",
    "\n",
    "\n",
    "I will use a correlation analysis between the features and the repetitive variables in each \n",
    "column as the criteria for the feature selection!!\n",
    "'''\n",
    "\n",
    "# Read and transform the training data!\n",
    "data_path=\"../input/house-prices-advanced-regression-techniques/train.csv\"\n",
    "# Note that these variables are for the feature selection and you can change them accordingly, in case you have a better r2 score.\n",
    "repetetive_number_percentage=0.7\n",
    "highest_correlation_coeefficiency=0.9\n",
    "\n",
    "def data_transform(data_path):\n",
    "    # Read the data\n",
    "    data_=pd.read_csv(data_path,sep=\",\")\n",
    "    # Remove the Id number\n",
    "    data_.drop([\"Id\"], inplace=True,axis=1)\n",
    "    # Transform the objects to numeric numbers\n",
    "    label_encoder = LabelEncoder()\n",
    "    for each in range(len(data_.columns)):\n",
    "        if data_[data_.columns[each]].dtype.name==\"object\":\n",
    "            data_[data_.columns[each]] =pd.Series(label_encoder.fit_transform(data_[data_.columns[each]].to_list()))\n",
    "    return data_\n",
    "data_=data_transform(data_path)\n",
    "\n",
    "'''\n",
    "I will do the removing of some features according to 2 things! \n",
    "1. The percentage of highest number of repetition in the variables\n",
    "2. The correlation between the variables are more than 90 percent or not?\n",
    "'''\n",
    "# Let me remove the repetitive variables!\n",
    "\n",
    "def remover_repetetive(data_,repetetive_number_percentage):\n",
    "    index_to_remove=[]\n",
    "    for each in range(len(data_.columns)):\n",
    "        t_=data_[data_.columns[each]].mode()[0]\n",
    "        num= (data_[data_.columns[each]].value_counts()[t_])/len(data_)\n",
    "        if num>repetetive_number_percentage:\n",
    "            index_to_remove.append(each)\n",
    "    data_ = data_.drop(data_.columns[index_to_remove],axis = 1)\n",
    "    return data_,index_to_remove\n",
    "data_,index_to_remove=remover_repetetive(data_,repetetive_number_percentage)\n",
    "\n",
    "# Now let me look at the correlations and then remove some of the similar variables!\n",
    "def remover_correlation_eff(data_,highest_correlation_coeefficiency):\n",
    "    corr = data_.corr()\n",
    "    numbers=[]\n",
    "    for each in range(len(corr)):\n",
    "        if each!=len(corr)-1:\n",
    "            names_=corr[corr.columns[each]][each+1:]\n",
    "            for score in names_.to_list():\n",
    "                if score>highest_correlation_coeefficiency:\n",
    "                   ind_=corr[corr.columns[each]].to_list().index(score)\n",
    "                   numbers.append(ind_)\n",
    "    rem=list(set(numbers))\n",
    "    data_ = data_.drop(data_.columns[rem],axis = 1)\n",
    "    return data_,rem\n",
    "data_,rem=remover_repetetive(data_,highest_correlation_coeefficiency)\n",
    "\n",
    "# Now, let me use these features and try to fit our data into different regression models!\n",
    "\n",
    "# Let me define the attributes and labels, split data  to training and test sets and replace missing values with the mean value!\n",
    "\n",
    "def generate_test_train(data_):\n",
    "    Attributes_=data_[data_.columns[:-1]]\n",
    "    Labels_=data_[data_.columns[-1:]]\n",
    "    # Let me convert Attributes and Labels dataframes to numpy array and scale my data!\n",
    "    Attributes= np.array(Attributes_)\n",
    "    Attributes=scale(Attributes)\n",
    "    Labels_=np.array(Labels_)\n",
    "    # Let  me now split my data to training set and test set!\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Attributes,Labels_, test_size=0.3,random_state=109) # 70% training and 30% test data!\n",
    "    # Let me replace the missing values with  the mean value using sklearn.impute function!\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    imp = imp.fit(X_train)\n",
    "    X_train= imp.transform(X_train)\n",
    "    X_test= imp.transform(X_test)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test= generate_test_train(data_)\n",
    "\n",
    "# Now, let me fit our data into linear regression model!\n",
    "def linear_regression_model(X_train, y_train,y_test):\n",
    "    reg = LinearRegression().fit(X_train, y_train)\n",
    "    y_pred_lr = reg.predict(X_test)\n",
    "\n",
    "    # Let me look at the r2 score!\n",
    "    rsquare_lr=metrics.r2_score(y_test, y_pred_lr)\n",
    "    return rsquare_lr,reg\n",
    "rsquare_lr,reg=linear_regression_model(X_train, y_train,y_test)\n",
    "print(\"My Linear Regression R square score is:\",rsquare_lr)\n",
    "\n",
    "\n",
    "# Now, let me fit our data into random forest regression model!\n",
    "def random_forest_regression_model(X_train, y_train,y_test):\n",
    "    regr_forest = RandomForestRegressor(max_depth=9, random_state=0)\n",
    "    regr_forest = regr_forest.fit(X_train, y_train)\n",
    "    y_pred_lr = regr_forest.predict(X_test)\n",
    "    # Let me look at the r2 score!\n",
    "    rsquare_rf=metrics.r2_score(y_test, y_pred_lr)\n",
    "    return rsquare_rf,regr_forest\n",
    "rsquare_rf,regr_forest=random_forest_regression_model(X_train, y_train,y_test)\n",
    "print(\"My Random Forest Regression R square score is:\",rsquare_rf)\n",
    "\n",
    "# Now, let me fit our data into\n",
    "def gradient_boosting_regression_model(X_train, y_train,y_test):\n",
    "    regr_gradient = GradientBoostingRegressor(max_depth=4, random_state=0)\n",
    "    regr_gradient = regr_gradient.fit(X_train, y_train)\n",
    "    y_pred_gb = regr_gradient.predict(X_test)\n",
    "    # Let me look at r2 score!\n",
    "    rsquare_gb=metrics.r2_score(y_test, y_pred_gb)\n",
    "    return rsquare_gb,regr_gradient\n",
    "rsquare_gb,regr_gradient=gradient_boosting_regression_model(X_train, y_train,y_test)\n",
    "print(\"My Gradient Boosting Regression R square score is:\",rsquare_gb)\n",
    "\n",
    "# For this, similar to our training data, we need to filter our testing data!\n",
    "\n",
    "# Let me transform the test data first!\n",
    "\n",
    "data_test_path_=\"../input/house-prices-advanced-regression-techniques/test.csv\"\n",
    "def data_transform(data_test_path_):\n",
    "    # Read the data\n",
    "    all_test = pd.read_csv(data_test_path_, sep=\",\")\n",
    "    # Remove the Id number\n",
    "    all_data= all_test.drop([\"Id\"],axis=1)\n",
    "    # Transform the objects to numeric numbers\n",
    "    label_encoder = LabelEncoder()\n",
    "    for each in range(len(all_data.columns)):\n",
    "        if all_data[all_data.columns[each]].dtype.name==\"object\":\n",
    "            all_data[all_data.columns[each]] =pd.Series(label_encoder.fit_transform(all_data[all_data.columns[each]].to_list()))\n",
    "    # Let me also take the index we used for the training data!\n",
    "    all_data = all_data.drop(all_data.columns[index_to_remove], axis=1)\n",
    "    all_data = all_data.drop(all_data.columns[rem], axis=1)\n",
    "\n",
    "    # Let me convert the test data attributes to array!\n",
    "    Attributes_test = np.array(all_data)\n",
    "    # Let me scale the attributes!\n",
    "    Attributes_test = scale(Attributes_test)\n",
    "\n",
    "    # Let me now replace the nan values with the mean!\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    imp = imp.fit(Attributes_test)\n",
    "    Attributes_test = imp.transform(Attributes_test)\n",
    "\n",
    "    return Attributes_test,all_test\n",
    "Attributes_test,all_test=data_transform(data_test_path_)\n",
    "\n",
    "# Now, we need to use this data for the testing in order to predict our labels, utilizing 3 of the algorithms!\n",
    "\n",
    "def test_function(Attributes_test,all_test,reg,regr_forest,regr_gradient):\n",
    "    # Let me use the trained linear regression model for the prediction!\n",
    "    y_tested_linear = reg.predict(Attributes_test)\n",
    "    all_test[\"Predictions_linear\"]=pd.DataFrame(y_tested_linear)\n",
    "\n",
    "    # Let me use the trained random forest regression model for the prediction!\n",
    "    y_tested_forest = regr_forest.predict(Attributes_test)\n",
    "    all_test[\"Predictions_forest\"]=pd.Series(y_tested_forest)\n",
    "\n",
    "    # Let me use the trained gradient boost regression model for the prediction!\n",
    "    y_tested_gradient = regr_gradient.predict(Attributes_test)\n",
    "    all_test[\"Predictions_gradient\"]=pd.Series(y_tested_gradient)\n",
    "\n",
    "    # Let me get the median of our predictions for the 3 of the algorithms!!\n",
    "    all_test[\"SalePrice\"]=all_test[[\"Predictions_linear\",\"Predictions_forest\",\"Predictions_gradient\"]].median(axis=1)\n",
    "    result_frame=all_test[[\"Id\",\"SalePrice\"]]\n",
    "\n",
    "    # Let me convert the result data frame to csv file\n",
    "    result_frame.to_csv(\"../working/sample_submission.csv\",sep=\",\",index_label=False,index=False)\n",
    "\n",
    "    return all_test\n",
    "all_test=test_function(Attributes_test,all_test,reg,regr_forest,regr_gradient)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19.452412,
   "end_time": "2022-07-11T06:25:50.227589",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-11T06:25:30.775177",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
